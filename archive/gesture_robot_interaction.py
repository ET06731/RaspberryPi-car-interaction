#!/usr/bin/env python3
"""
ğŸ¤– æ™ºèƒ½æ‰‹åŠ¿äº¤äº’å°è½¦ - MediaPipe ç‰ˆ

åŠŸèƒ½:
1. ä½¿ç”¨ MediaPipe è¿›è¡Œæ‰‹åŠ¿è¯†åˆ« (æ‰‹æŒ/æ‹³å¤´/å‰ªåˆ€æ‰‹/ç‚¹èµ/æ•°å­—)
2. OLED æ˜¾ç¤ºå¯¹åº”çš„è¡¨æƒ…å’Œåé¦ˆ
3. èˆµæœºäº‘å°è·Ÿéšæ‰‹åŠ¿ç§»åŠ¨ (æŠ¬å¤´/ä½å¤´/å·¦è½¬/å³è½¬)
4. åƒä¸€ä¸ªæœ‰æƒ…æ„Ÿçš„æœºå™¨äºº

æ‰‹åŠ¿å¯¹åº”:
- âœ‹ å¼ å¼€æ‰‹æŒ: å‹å¥½æ¨¡å¼ï¼Œèˆµæœºç¯é¡¾å››å‘¨
- âœŠ æ¡æ‹³: è­¦æƒ•æ¨¡å¼ï¼Œèˆµæœºé”å®š
- âœŒï¸ å‰ªåˆ€æ‰‹: å¼€å¿ƒï¼Œèˆµæœºæ‘‡æ‘†
- ğŸ‘ ç‚¹èµ: ç¡®è®¤ï¼Œç‚¹å¤´
- ğŸ‘ å€’èµ: æ‘‡å¤´
- â˜ï¸ é£ŸæŒ‡å‘ä¸Š: æŠ¬å¤´çœ‹
- ğŸ‘‡ é£ŸæŒ‡å‘ä¸‹: ä½å¤´çœ‹
- ğŸ‘ˆ ğŸ‘‰ å·¦å³æŒ‡: å·¦å³è½¬å¤´
- ğŸ–ï¸ äº”æŒ‡å¼ å¼€: æ‰“æ‹›å‘¼ï¼Œå·¦å³æ‘‡æ‘†

è¿è¡Œ: cd ~/rpi-car-project && ~/.local/bin/uv run python3 gesture_robot_interaction.py
"""

import os
import cv2
import time
import threading
import numpy as np
from collections import Counter
from luma.core.interface.serial import i2c
from luma.oled.device import ssd1306
from PIL import Image, ImageDraw, ImageFont

# å°è¯•å¯¼å…¥ RPi.GPIOï¼Œå¦‚æœåœ¨éæ ‘è“æ´¾ç¯å¢ƒåˆ™ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
try:
    import RPi.GPIO as GPIO
    GPIO_AVAILABLE = True
except ImportError:
    GPIO_AVAILABLE = False
    print("[è­¦å‘Š] RPi.GPIO ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

# å°è¯•å¯¼å…¥ MediaPipe
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    print("[é”™è¯¯] MediaPipe æœªå®‰è£…")


# ==================== ç¡¬ä»¶é…ç½® ====================
# èˆµæœºå¼•è„š (BCM ç¼–ç )
SERVO_PIN = 23

# èˆµæœºè§’åº¦èŒƒå›´
SERVO_CENTER = 90      # ä¸­é—´ä½ç½®
SERVO_LEFT_MAX = 0     # æœ€å·¦
SERVO_RIGHT_MAX = 180  # æœ€å³
SERVO_UP_MAX = 60      # æŠ¬å¤´ (æ°´å¹³èˆµæœºçš„è¯æ˜¯å¦ä¸€ä¸ªè½´)
SERVO_DOWN_MAX = 120   # ä½å¤´

# æ‰‹åŠ¿å¹³æ»‘çª—å£å¤§å°
GESTURE_WINDOW_SIZE = 5


# ==================== è¡¨æƒ…é…ç½® ====================
ROBOT_EXPRESSIONS = {
    'idle': {
        'emoji': '(-_-)',
        'name': 'å¾…æœº',
        'action': 'ç­‰å¾…æŒ‡ä»¤...',
        'servo_action': 'center'
    },
    'palm': {
        'emoji': '(âœ§Ï‰âœ§)',
        'name': 'æ‰‹æŒ',
        'action': 'ä½ å¥½ï¼æœ‹å‹',
        'servo_action': 'scan'  # æ‰«æå››å‘¨
    },
    'fist': {
        'emoji': '(â—£_â—¢)',
        'name': 'æ¡æ‹³',
        'action': 'æ£€æµ‹åˆ°å¨èƒ',
        'servo_action': 'lock'  # é”å®š
    },
    'peace': {
        'emoji': '(â— â€¿â— )',
        'name': 'å‰ªåˆ€æ‰‹',
        'action': 'è€¶ï¼å¼€å¿ƒ',
        'servo_action': 'sway'  # æ‘‡æ‘†
    },
    'thumbs_up': {
        'emoji': '(ï½¡â—•â€¿â—•ï½¡)',
        'name': 'ç‚¹èµ',
        'action': 'æ”¶åˆ°ï¼',
        'servo_action': 'nod'  # ç‚¹å¤´
    },
    'thumbs_down': {
        'emoji': '(â—•ï¸µâ—•)',
        'name': 'å€’èµ',
        'action': 'ä¸å¤ªè®¤åŒ',
        'servo_action': 'shake'  # æ‘‡å¤´
    },
    'point_up': {
        'emoji': '(âŠ™_âŠ™)',
        'name': 'æŒ‡ä¸Š',
        'action': 'å¾€ä¸Šçœ‹',
        'servo_action': 'look_up'  # æŠ¬å¤´
    },
    'point_down': {
        'emoji': '(Â¬_Â¬)',
        'name': 'æŒ‡ä¸‹',
        'action': 'å¾€ä¸‹çœ‹',
        'servo_action': 'look_down'  # ä½å¤´
    },
    'point_left': {
        'emoji': '(â—£_â—¢)',
        'name': 'æŒ‡å·¦',
        'action': 'çœ‹å·¦è¾¹',
        'servo_action': 'look_left'  # å·¦è½¬
    },
    'point_right': {
        'emoji': '(â—¢_â—£)',
        'name': 'æŒ‡å³',
        'action': 'çœ‹å³è¾¹',
        'servo_action': 'look_right'  # å³è½¬
    },
    'ok': {
        'emoji': '(âŒ’â€¿âŒ’)',
        'name': 'OK',
        'action': 'æ²¡é—®é¢˜',
        'servo_action': 'nod_twice'  # ç‚¹ä¸¤ä¸‹å¤´
    },
    'unknown': {
        'emoji': '(âŠ™_âŠ™)ï¼Ÿ',
        'name': 'æœªçŸ¥',
        'action': 'ä¸å¤ªæ˜ç™½',
        'servo_action': 'confused'  # ç–‘æƒ‘æ‘‡å¤´
    }
}


# ==================== èˆµæœºæ§åˆ¶å™¨ ====================
class ServoController:
    """èˆµæœºäº‘å°æ§åˆ¶å™¨"""
    
    def __init__(self, pin=SERVO_PIN):
        self.pin = pin
        self.current_angle = SERVO_CENTER
        self.target_angle = SERVO_CENTER
        self.running = False
        self.thread = None
        self.lock = threading.Lock()
        self.action_lock = threading.Lock()  # åŠ¨ä½œæ‰§è¡Œé”
        self.is_busy = False  # æ˜¯å¦æ­£åœ¨æ‰§è¡ŒåŠ¨ä½œ
        
        if GPIO_AVAILABLE:
            try:
                GPIO.setmode(GPIO.BCM)
                GPIO.setwarnings(False)
                GPIO.setup(self.pin, GPIO.OUT)
                self.pwm = GPIO.PWM(self.pin, 50)  # 50Hz
                self.pwm.start(0)
                self._set_angle(SERVO_CENTER)
                print("[OK] èˆµæœºåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"[é”™è¯¯] èˆµæœºåˆå§‹åŒ–å¤±è´¥: {e}")
                self.pwm = None
        else:
            self.pwm = None
            print("[æ¨¡æ‹Ÿ] èˆµæœºæ§åˆ¶å™¨ (æ— ç¡¬ä»¶)")
    
    def _angle_to_duty_cycle(self, angle):
        """å°†è§’åº¦è½¬æ¢ä¸ºå ç©ºæ¯” (2.5-12.5 å¯¹åº” 0-180åº¦)"""
        return 2.5 + (angle / 180.0) * 10.0
    
    def _set_angle(self, angle):
        """ç›´æ¥è®¾ç½®è§’åº¦"""
        angle = max(SERVO_LEFT_MAX, min(SERVO_RIGHT_MAX, angle))
        if self.pwm:
            duty = self._angle_to_duty_cycle(angle)
            self.pwm.ChangeDutyCycle(duty)
            time.sleep(0.02)
            self.pwm.ChangeDutyCycle(0)  # åœæ­¢ä¿¡å·ï¼Œé˜²æ­¢æŠ–åŠ¨
        self.current_angle = angle
    
    def set_angle(self, angle, smooth=True):
        """è®¾ç½®ç›®æ ‡è§’åº¦"""
        with self.lock:
            self.target_angle = max(SERVO_LEFT_MAX, min(SERVO_RIGHT_MAX, angle))
    
    def get_current_angle(self):
        """è·å–å½“å‰è§’åº¦"""
        with self.lock:
            return self.current_angle
    
    def _smooth_move_thread(self):
        """å¹³æ»‘ç§»åŠ¨çº¿ç¨‹"""
        while self.running:
            with self.lock:
                diff = self.target_angle - self.current_angle
            
            if abs(diff) > 1:
                step = 2 if diff > 0 else -2
                new_angle = self.current_angle + step
                self._set_angle(new_angle)
            else:
                time.sleep(0.02)
    
    def start(self):
        """å¯åŠ¨å¹³æ»‘æ§åˆ¶çº¿ç¨‹"""
        if not self.running:
            self.running = True
            self.thread = threading.Thread(target=self._smooth_move_thread, daemon=True)
            self.thread.start()
    
    def stop(self):
        """åœæ­¢èˆµæœº"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=1)
        if self.pwm:
            self.pwm.stop()
    
    # ==================== æƒ…æ„ŸåŠ¨ä½œ ====================
    def action_center(self):
        """å›ä¸­"""
        self.set_angle(SERVO_CENTER)
    
    def action_look_left(self):
        """å‘å·¦çœ‹"""
        self.set_angle(SERVO_LEFT_MAX + 30)
    
    def action_look_right(self):
        """å‘å³çœ‹"""
        self.set_angle(SERVO_RIGHT_MAX - 30)
    
    def action_nod(self):
        """ç‚¹å¤´ (å¿«é€Ÿå·¦å³æ‘†åŠ¨)"""
        if not GPIO_AVAILABLE:
            return
        for _ in range(2):
            self._set_angle(SERVO_CENTER - 20)
            time.sleep(0.15)
            self._set_angle(SERVO_CENTER + 20)
            time.sleep(0.15)
        self._set_angle(SERVO_CENTER)
    
    def action_shake(self):
        """æ‘‡å¤´ (å·¦å³æ‘†åŠ¨)"""
        if not GPIO_AVAILABLE:
            return
        for _ in range(3):
            self._set_angle(SERVO_LEFT_MAX + 45)
            time.sleep(0.2)
            self._set_angle(SERVO_RIGHT_MAX - 45)
            time.sleep(0.2)
        self._set_angle(SERVO_CENTER)
    
    def action_sway(self):
        """æ‘‡æ‘† (æ…¢é€Ÿæ‘†åŠ¨)"""
        if not GPIO_AVAILABLE:
            return
        for _ in range(2):
            self._set_angle(SERVO_CENTER - 30)
            time.sleep(0.3)
            self._set_angle(SERVO_CENTER + 30)
            time.sleep(0.3)
        self._set_angle(SERVO_CENTER)
    
    def action_scan(self):
        """æ‰«æ (ç¯é¡¾å››å‘¨)"""
        if not GPIO_AVAILABLE:
            return
        for angle in range(SERVO_LEFT_MAX, SERVO_RIGHT_MAX + 1, 5):
            self._set_angle(angle)
            time.sleep(0.05)
        for angle in range(SERVO_RIGHT_MAX, SERVO_LEFT_MAX - 1, -5):
            self._set_angle(angle)
            time.sleep(0.05)
        self._set_angle(SERVO_CENTER)
    
    def action_lock(self):
        """é”å®š (å±…ä¸­ä¸åŠ¨)"""
        self._set_angle(SERVO_CENTER)
    
    def action_confused(self):
        """ç–‘æƒ‘ (å¿«é€Ÿå°å¹…åº¦æ‘†åŠ¨)"""
        if not GPIO_AVAILABLE:
            return
        for _ in range(4):
            self._set_angle(SERVO_CENTER - 10)
            time.sleep(0.1)
            self._set_angle(SERVO_CENTER + 10)
            time.sleep(0.1)
        self._set_angle(SERVO_CENTER)
    
    def execute_action(self, action_name):
        """æ‰§è¡Œæƒ…æ„ŸåŠ¨ä½œ"""
        action_method = getattr(self, f'action_{action_name}', None)
        if action_method:
            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ä¸»å¾ªç¯
            thread = threading.Thread(target=action_method, daemon=True)
            thread.start()


# ==================== OLED æ˜¾ç¤ºå™¨ ====================
class OLEDDisplay:
    """OLED è¡¨æƒ…æ˜¾ç¤ºå™¨"""
    
    def __init__(self, port=1, address=0x3C):
        try:
            serial = i2c(port=port, address=address)
            self.device = ssd1306(serial, width=128, height=64)
            self.connected = True
            self._load_fonts()
            print("[OK] OLED å·²è¿æ¥")
        except Exception as e:
            self.connected = False
            self.device = None
            print(f"[è­¦å‘Š] OLED è¿æ¥å¤±è´¥: {e}")
    
    def _load_fonts(self):
        """åŠ è½½å­—ä½“"""
        try:
            self.font_emoji = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 24)
            self.font_name = ImageFont.truetype("/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc", 14)
            self.font_action = ImageFont.truetype("/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc", 11)
        except:
            try:
                self.font_emoji = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 24)
                self.font_name = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 14)
                self.font_action = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 11)
            except:
                self.font_emoji = ImageFont.load_default()
                self.font_name = ImageFont.load_default()
                self.font_action = ImageFont.load_default()
    
    def show_expression(self, emoji, name, action):
        """æ˜¾ç¤ºè¡¨æƒ…"""
        if not self.connected:
            return
        
        image = Image.new('1', (128, 64))
        draw = ImageDraw.Draw(image)
        
        # æ¸…å±
        draw.rectangle((0, 0, 127, 63), outline=0, fill=0)
        
        # ç»˜åˆ¶è¡¨æƒ… (å±…ä¸­)
        bbox = draw.textbbox((0, 0), emoji, font=self.font_emoji)
        text_width = bbox[2] - bbox[0]
        x = (128 - text_width) // 2
        draw.text((x, 0), emoji, font=self.font_emoji, fill=255)
        
        # ç»˜åˆ¶æ‰‹åŠ¿åç§°
        bbox = draw.textbbox((0, 0), name, font=self.font_name)
        text_width = bbox[2] - bbox[0]
        x = (128 - text_width) // 2
        draw.text((x, 30), name, font=self.font_name, fill=255)
        
        # ç»˜åˆ¶åŠ¨ä½œæè¿°
        bbox = draw.textbbox((0, 0), action, font=self.font_action)
        text_width = bbox[2] - bbox[0]
        x = (128 - text_width) // 2
        draw.text((x, 48), action, font=self.font_action, fill=255)
        
        self.device.display(image)
    
    def clear(self):
        """æ¸…å±"""
        if self.connected:
            self.device.clear()


# ==================== æ‰‹åŠ¿è¯†åˆ«å™¨ ====================
class GestureRecognizer:
    """MediaPipe æ‰‹åŠ¿è¯†åˆ«å™¨"""
    
    def __init__(self):
        if not MEDIAPIPE_AVAILABLE:
            raise RuntimeError("MediaPipe æœªå®‰è£…")
        
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
        
        print("[OK] MediaPipe Hands åˆå§‹åŒ–æˆåŠŸ")
    
    def recognize(self, frame):
        """
        è¯†åˆ«æ‰‹åŠ¿
        è¿”å›: (gesture_name, annotated_frame)
        """
        # è½¬æ¢é¢œè‰²ç©ºé—´
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.hands.process(rgb_frame)
        
        gesture = 'idle'
        
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
                self.mp_drawing.draw_landmarks(
                    frame,
                    hand_landmarks,
                    self.mp_hands.HAND_CONNECTIONS,
                    self.mp_drawing_styles.get_default_hand_landmarks_style(),
                    self.mp_drawing_styles.get_default_hand_connections_style()
                )
                
                # è¯†åˆ«æ‰‹åŠ¿
                gesture = self._classify_gesture(hand_landmarks)
        
        return gesture, frame
    
    def _classify_gesture(self, landmarks):
        """æ ¹æ®å…³é”®ç‚¹åˆ†ç±»æ‰‹åŠ¿"""
        # è·å–å…³é”®ç‚¹åæ ‡
        points = []
        for landmark in landmarks.landmark:
            points.append((landmark.x, landmark.y, landmark.z))
        
        # æ‰‹æŒ‡å…³é”®ç‚¹ç´¢å¼•
        THUMB_TIP = 4
        INDEX_TIP = 8
        MIDDLE_TIP = 12
        RING_TIP = 16
        PINKY_TIP = 20
        
        WRIST = 0
        INDEX_MCP = 5
        MIDDLE_MCP = 9
        RING_MCP = 13
        PINKY_MCP = 17
        
        # è®¡ç®—æ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´ (æŒ‡å°–åˆ°æ‰‹è…•çš„è·ç¦» > æŒ‡æ ¹åˆ°æ‰‹è…•çš„è·ç¦»)
        def is_finger_extended(tip_idx, mcp_idx):
            tip_to_wrist = np.linalg.norm(np.array(points[tip_idx]) - np.array(points[WRIST]))
            mcp_to_wrist = np.linalg.norm(np.array(points[mcp_idx]) - np.array(points[WRIST]))
            return tip_to_wrist > mcp_to_wrist * 1.3
        
        # åˆ¤æ–­æ¯ä¸ªæ‰‹æŒ‡çŠ¶æ€
        thumb_extended = points[THUMB_TIP][0] > points[THUMB_TIP - 2][0] if points[THUMB_TIP][0] > points[WRIST][0] else points[THUMB_TIP][0] < points[THUMB_TIP - 2][0]
        index_extended = is_finger_extended(INDEX_TIP, INDEX_MCP)
        middle_extended = is_finger_extended(MIDDLE_TIP, MIDDLE_MCP)
        ring_extended = is_finger_extended(RING_TIP, RING_MCP)
        pinky_extended = is_finger_extended(PINKY_TIP, PINKY_MCP)
        
        extended_fingers = sum([index_extended, middle_extended, ring_extended, pinky_extended])
        
        # æ‰‹åŠ¿åˆ†ç±»é€»è¾‘
        if extended_fingers == 0:
            return 'fist'  # æ¡æ‹³
        elif extended_fingers == 1:
            if index_extended:
                # åˆ¤æ–­é£ŸæŒ‡æŒ‡å‘æ–¹å‘
                dx = points[INDEX_TIP][0] - points[WRIST][0]
                dy = points[INDEX_TIP][1] - points[WRIST][1]
                if abs(dx) > abs(dy):
                    return 'point_right' if dx > 0 else 'point_left'
                else:
                    return 'point_down' if dy > 0 else 'point_up'
            elif thumb_extended:
                # åˆ¤æ–­æ‹‡æŒ‡æ–¹å‘
                if points[THUMB_TIP][1] < points[THUMB_TIP - 2][1]:
                    return 'thumbs_up'
                else:
                    return 'thumbs_down'
            return 'unknown'
        elif extended_fingers == 2:
            if index_extended and middle_extended:
                return 'peace'  # å‰ªåˆ€æ‰‹
            elif thumb_extended and index_extended:
                return 'ok'  # OK
            return 'unknown'
        elif extended_fingers >= 4:
            return 'palm'  # æ‰‹æŒ
        
        return 'unknown'
    
    def close(self):
        """é‡Šæ”¾èµ„æº"""
        self.hands.close()


# ==================== æ‰‹åŠ¿å¹³æ»‘å™¨ ====================
class GestureSmoother:
    """æ‰‹åŠ¿å¹³æ»‘å™¨ï¼Œå‡å°‘æŠ–åŠ¨"""
    
    def __init__(self, window_size=GESTURE_WINDOW_SIZE, min_confidence=3):
        self.window_size = window_size
        self.min_confidence = min_confidence
        self.history = []
        self.stable_gesture = 'idle'
    
    def update(self, raw_gesture):
        """æ›´æ–°å¹¶è¿”å›ç¨³å®šæ‰‹åŠ¿"""
        self.history.append(raw_gesture)
        if len(self.history) > self.window_size:
            self.history.pop(0)
        
        if len(self.history) < self.min_confidence:
            return None
        
        # ç»Ÿè®¡æœ€å¸¸è§çš„æ‰‹åŠ¿
        counter = Counter(self.history)
        most_common = counter.most_common(1)[0]
        gesture, count = most_common
        
        if count >= self.min_confidence and gesture != self.stable_gesture:
            self.stable_gesture = gesture
            return gesture
        
        return None
    
    def get_stable(self):
        """è·å–å½“å‰ç¨³å®šæ‰‹åŠ¿"""
        return self.stable_gesture
    
    def reset(self):
        """é‡ç½®å†å²"""
        self.history = []
        self.stable_gesture = 'idle'


# ==================== ä¸»ç¨‹åº ====================
class GestureRobotInteraction:
    """æ‰‹åŠ¿äº¤äº’æœºå™¨äººä¸»ç±»"""
    
    def __init__(self, camera_index=0, headless=False):
        print("=" * 60)
        print("  ğŸ¤– æ™ºèƒ½æ‰‹åŠ¿äº¤äº’å°è½¦")
        print("  MediaPipe æ‰‹åŠ¿è¯†åˆ« + èˆµæœºäº‘å° + OLED è¡¨æƒ…")
        print("=" * 60)
        print()
        
        # æ£€æµ‹æ˜¯å¦æœ‰å›¾å½¢ç•Œé¢
        self.headless = headless or not os.environ.get('DISPLAY')
        if self.headless:
            print("[ä¿¡æ¯] æ— å›¾å½¢ç•Œé¢æ¨¡å¼ (headless)")
            print("[ä¿¡æ¯] OLED å’Œ èˆµæœºæ­£å¸¸å·¥ä½œï¼Œä¸æ˜¾ç¤ºçª—å£")
        print()
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.camera = self._init_camera(camera_index)
        if not self.camera or not self.camera.isOpened():
            raise RuntimeError("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        
        self.camera_index = camera_index
        self.gesture_recognizer = GestureRecognizer()
        self.oled = OLEDDisplay()
        self.servo = ServoController()
        self.smoother = GestureSmoother()
        
        self.running = False
        self.current_gesture = 'idle'
        self.frame = None
        self.lock = threading.Lock()
        
        print("[OK] æ‰€æœ‰æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        print()
        print("æ‰‹åŠ¿æŒ‡ä»¤:")
        print("  âœ‹ æ‰‹æŒå¼ å¼€ - å‹å¥½æ¨¡å¼ï¼Œç¯é¡¾å››å‘¨")
        print("  âœŠ æ¡æ‹³     - è­¦æƒ•æ¨¡å¼ï¼Œé”å®š")
        print("  âœŒï¸ å‰ªåˆ€æ‰‹   - å¼€å¿ƒæ‘‡æ‘†")
        print("  ğŸ‘ ç‚¹èµ    - ç¡®è®¤ï¼Œç‚¹å¤´")
        print("  ğŸ‘ å€’èµ    - æ‘‡å¤´")
        print("  â˜ï¸ æŒ‡ä¸Š     - æŠ¬å¤´")
        print("  ğŸ‘‡ æŒ‡ä¸‹     - ä½å¤´")
        print("  ğŸ‘ˆ ğŸ‘‰ æŒ‡å·¦å³ - å·¦å³è½¬å¤´")
        print()
        if not self.headless:
            print("æŒ‰ Q é€€å‡º")
        else:
            print("æŒ‰ Ctrl+C é€€å‡º")
        print()
    
    def _find_available_camera(self):
        """è‡ªåŠ¨æŸ¥æ‰¾å¯ç”¨çš„æ‘„åƒå¤´"""
        # é¦–å…ˆå°è¯•æŒ‡å®šçš„ç´¢å¼•
        for idx in [0, 1]:
            print(f"[ä¿¡æ¯] å°è¯• /dev/video{idx}...")
            cap = cv2.VideoCapture(idx)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    print(f"[OK] æ‰¾åˆ°å¯ç”¨æ‘„åƒå¤´ /dev/video{idx}: {frame.shape}")
                    cap.release()
                    return idx
                cap.release()
        
        return None
    
    def _init_camera(self, camera_index):
        """åˆå§‹åŒ–æ‘„åƒå¤´ï¼Œå¸¦é‡è¯•é€»è¾‘"""
        # å¦‚æœæŒ‡å®šäº†ç´¢å¼•ï¼Œå…ˆå°è¯•ï¼›å¦åˆ™è‡ªåŠ¨æŸ¥æ‰¾
        if camera_index is not None:
            indices_to_try = [camera_index] + [i for i in [0, 1] if i != camera_index]
        else:
            indices_to_try = [0, 1]
        
        for idx in indices_to_try:
            print(f"[ä¿¡æ¯] åˆå§‹åŒ–æ‘„åƒå¤´ /dev/video{idx}...")
            
            for attempt in range(2):
                cap = cv2.VideoCapture(idx)
                
                if not cap.isOpened():
                    print(f"[è­¦å‘Š] ç¬¬ {attempt+1} æ¬¡å°è¯•å¤±è´¥ï¼Œé‡è¯•...")
                    time.sleep(1)
                    continue
                
                # è¯»å–ä¸€å¸§æµ‹è¯•ï¼ˆä¸è®¾ç½®å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤ï¼‰
                ret, frame = cap.read()
                if ret and frame is not None:
                    print(f"[OK] æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ: {frame.shape}")
                    self.camera_index = idx  # ä¿å­˜å®é™…ä½¿ç”¨çš„ç´¢å¼•
                    return cap
                
                cap.release()
                print(f"[è­¦å‘Š] ç¬¬ {attempt+1} æ¬¡æµ‹è¯•è¯»å–å¤±è´¥ï¼Œé‡è¯•...")
                time.sleep(1)
        
        return None
    
    def _restart_camera(self):
        """é‡å¯æ‘„åƒå¤´"""
        print("[ä¿¡æ¯] å°è¯•é‡å¯æ‘„åƒå¤´...")
        
        with self.lock:
            if self.camera:
                self.camera.release()
        
        time.sleep(1)
        
        self.camera = self._init_camera(self.camera_index)
        
        if self.camera and self.camera.isOpened():
            print("[OK] æ‘„åƒå¤´é‡å¯æˆåŠŸ")
            return True
        else:
            print("[é”™è¯¯] æ‘„åƒå¤´é‡å¯å¤±è´¥")
            return False
    
    def _camera_loop(self):
        """æ‘„åƒå¤´é‡‡é›†å¾ªç¯ - å¸¦å¸§ç‡é™åˆ¶å’Œè‡ªåŠ¨æ¢å¤"""
        frame_interval = 1.0 / 10  # é™åˆ¶ 10 FPSï¼Œå‡è½» CPU å’Œ USB å¸¦å®½
        last_frame_time = 0
        frame_count = 0
        last_fps_time = time.time()
        consecutive_failures = 0
        max_failures = 10
        
        while self.running:
            current_time = time.time()
            
            # å¸§ç‡é™åˆ¶
            if current_time - last_frame_time < frame_interval:
                time.sleep(0.005)
                continue
            
            last_frame_time = current_time
            
            # æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æœ‰æ•ˆ
            if not self.camera or not self.camera.isOpened():
                print("[é”™è¯¯] æ‘„åƒå¤´å·²æ–­å¼€")
                if not self._restart_camera():
                    time.sleep(2)
                    continue
                consecutive_failures = 0
            
            ret, frame = self.camera.read()
            if not ret or frame is None:
                consecutive_failures += 1
                if consecutive_failures >= max_failures:
                    print(f"[é”™è¯¯] è¿ç»­ {max_failures} æ¬¡è¯»å–å¤±è´¥ï¼Œå°è¯•é‡å¯æ‘„åƒå¤´")
                    self._restart_camera()
                    consecutive_failures = 0
                else:
                    print(f"[è­¦å‘Š] æ‘„åƒå¤´è¯»å–å¤±è´¥ ({consecutive_failures}/{max_failures})")
                time.sleep(0.1)
                continue
            
            # æˆåŠŸè¯»å–ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
            consecutive_failures = 0
            
            # é•œåƒç¿»è½¬
            frame = cv2.flip(frame, 1)
            
            # è¯†åˆ«æ‰‹åŠ¿ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
            try:
                gesture, annotated_frame = self.gesture_recognizer.recognize(frame)
            except Exception as e:
                print(f"[é”™è¯¯] æ‰‹åŠ¿è¯†åˆ«å¤±è´¥: {e}")
                gesture = 'idle'
                annotated_frame = frame
            
            with self.lock:
                self.current_gesture = gesture
                self.frame = annotated_frame
            
            # FPS ç»Ÿè®¡
            frame_count += 1
            if current_time - last_fps_time >= 5.0:
                fps = frame_count / (current_time - last_fps_time)
                print(f"[æ€§èƒ½] æ‘„åƒå¤´ FPS: {fps:.1f}")
                frame_count = 0
                last_fps_time = current_time
                
                # å¦‚æœ FPS å¤ªä½ï¼Œå°è¯•é‡å¯æ‘„åƒå¤´
                if fps < 5.0:
                    print("[è­¦å‘Š] æ‘„åƒå¤´ FPS è¿‡ä½ï¼Œå°è¯•é‡å¯")
                    self._restart_camera()
    
    def _update_display(self, gesture):
        """æ›´æ–° OLED æ˜¾ç¤ºå’ŒèˆµæœºåŠ¨ä½œ"""
        if gesture not in ROBOT_EXPRESSIONS:
            gesture = 'unknown'
        
        expr = ROBOT_EXPRESSIONS[gesture]
        
        # æ›´æ–° OLED
        self.oled.show_expression(expr['emoji'], expr['name'], expr['action'])
        
        # æ‰§è¡ŒèˆµæœºåŠ¨ä½œ
        self.servo.execute_action(expr['servo_action'])
        
        print(f"[è¯†åˆ«] {expr['name']} {expr['emoji']} - {expr['action']}")
    
    def run(self):
        """ä¸»å¾ªç¯"""
        self.running = True
        
        # å¯åŠ¨æ‘„åƒå¤´çº¿ç¨‹
        camera_thread = threading.Thread(target=self._camera_loop, daemon=True)
        camera_thread.start()
        
        # å¯åŠ¨èˆµæœºå¹³æ»‘æ§åˆ¶
        self.servo.start()
        
        # åˆå§‹åŒ–æ˜¾ç¤º
        self._update_display('idle')
        
        last_gesture = 'idle'
        last_action_time = time.time()
        gesture_start_time = time.time()
        action_cooldown = 2.0  # åŠ¨ä½œå†·å´æ—¶é—´ï¼ˆç§’ï¼‰
        last_health_check = time.time()
        loop_count = 0
        
        print("[è¿è¡Œä¸­] è¯·åœ¨æ‘„åƒå¤´å‰å±•ç¤ºæ‰‹åŠ¿...")
        print("[æç¤º] æ¯æ¬¡åŠ¨ä½œåæœ‰ 2 ç§’å†·å´æ—¶é—´")
        
        try:
            while self.running:
                loop_start = time.time()
                loop_count += 1
                
                with self.lock:
                    gesture = self.current_gesture
                    frame = self.frame
                
                # å¹³æ»‘æ‰‹åŠ¿
                stable_gesture = self.smoother.update(gesture)
                current_time = time.time()
                
                # æ£€æµ‹åˆ°æ‰‹åŠ¿å˜åŒ–æˆ–ä¿æŒæ‰‹åŠ¿è¶…è¿‡å†·å´æ—¶é—´
                should_trigger = False
                
                if stable_gesture:
                    if stable_gesture != last_gesture:
                        # æ‰‹åŠ¿å‘ç”Ÿå˜åŒ–
                        should_trigger = True
                        gesture_start_time = current_time
                    elif stable_gesture != 'idle' and (current_time - last_action_time) > action_cooldown:
                        # ä¿æŒéå¾…æœºæ‰‹åŠ¿è¶…è¿‡å†·å´æ—¶é—´ï¼Œé‡å¤è§¦å‘
                        should_trigger = True
                        print(f"[é‡å¤è§¦å‘] ä¿æŒ {stable_gesture} æ‰‹åŠ¿ {action_cooldown} ç§’")
                
                if should_trigger:
                    self._update_display(stable_gesture)
                    last_gesture = stable_gesture
                    last_action_time = current_time
                
                # å¦‚æœé•¿æ—¶é—´æ²¡æœ‰æ£€æµ‹åˆ°æ‰‹åŠ¿ï¼Œé‡ç½®ä¸ºå¾…æœº
                if last_gesture != 'idle' and gesture != last_gesture and (current_time - gesture_start_time) > 3.0:
                    print(f"[ä¸¢å¤±æ‰‹åŠ¿] å›åˆ°å¾…æœºçŠ¶æ€")
                    self.smoother.reset()
                    last_gesture = 'idle'
                    self._update_display('idle')
                
                # æ˜¾ç¤ºç”»é¢ï¼ˆä»…åœ¨å›¾å½¢ç•Œé¢æ¨¡å¼ä¸‹ï¼‰
                if not self.headless and frame is not None:
                    stable = self.smoother.get_stable()
                    cv2.putText(frame, f"Gesture: {gesture}", (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(frame, f"Stable: {stable}", (10, 60),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                    
                    # æ˜¾ç¤ºå†·å´çŠ¶æ€
                    cooldown_remaining = max(0, action_cooldown - (current_time - last_action_time))
                    if cooldown_remaining > 0:
                        cv2.putText(frame, f"Cooldown: {cooldown_remaining:.1f}s", (10, 90),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                    
                    cv2.imshow("Gesture Robot", frame)
                    
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                
                # å®šæœŸå¥åº·æ£€æŸ¥ï¼ˆæ¯ 10 ç§’ï¼‰
                if current_time - last_health_check >= 10.0:
                    loop_time = current_time - last_health_check
                    loop_fps = loop_count / loop_time
                    print(f"[å¥åº·æ£€æŸ¥] ä¸»å¾ªç¯ FPS: {loop_fps:.1f}, å¾ªç¯æ¬¡æ•°: {loop_count}")
                    
                    # å¦‚æœä¸»å¾ªç¯ FPS å¤ªä½ï¼Œè¯´æ˜æœ‰é—®é¢˜
                    if loop_fps < 20:
                        print("[è­¦å‘Š] ä¸»å¾ªç¯æ€§èƒ½ä¸‹é™ï¼Œå°è¯•æ¸…ç†èµ„æº...")
                        self.smoother.reset()  # é‡ç½®æ‰‹åŠ¿å†å²
                    
                    last_health_check = current_time
                    loop_count = 0
                
                # è®¡ç®—æœ¬æ¬¡å¾ªç¯è€—æ—¶ï¼ŒåŠ¨æ€è°ƒæ•´ç¡çœ æ—¶é—´
                loop_duration = time.time() - loop_start
                sleep_time = max(0, 0.03 - loop_duration)
                if sleep_time > 0:
                    time.sleep(sleep_time)
        
        except KeyboardInterrupt:
            print("\n[ä¿¡æ¯] æ”¶åˆ°ä¸­æ–­ä¿¡å·")
        
        finally:
            self.shutdown()
    
    def shutdown(self):
        """å…³é—­æ‰€æœ‰èµ„æº"""
        print("\n[ä¿¡æ¯] æ­£åœ¨å…³é—­...")
        self.running = False
        
        self.camera.release()
        self.gesture_recognizer.close()
        self.oled.clear()
        self.servo.stop()
        
        if GPIO_AVAILABLE:
            GPIO.cleanup()
        
        cv2.destroyAllWindows()
        print("[OK] å·²å®‰å…¨é€€å‡º")


# ==================== å…¥å£ ====================
if __name__ == "__main__":
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    headless = '--headless' in sys.argv or '-h' in sys.argv
    
    try:
        robot = GestureRobotInteraction(camera_index=0, headless=headless)
        robot.run()
    except Exception as e:
        print(f"[é”™è¯¯] {e}")
        import traceback
        traceback.print_exc()
