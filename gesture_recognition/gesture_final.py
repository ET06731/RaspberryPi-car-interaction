#!/usr/bin/env python3
"""
æ‰‹åŠ¿è¯†åˆ«ç»ˆæä¼˜åŒ–ç‰ˆ - è§£å†³æ¡æ‹³è¯†åˆ«é—®é¢˜

æ ¸å¿ƒæ”¹è¿›:
1. æ¡æ‹³æ¡ä»¶æ”¾å®½åˆ°: ç¼ºé™·æ•° <= 2 (åŸç‰ˆæ˜¯ <= 1)
2. æ·»åŠ é¢ç§¯é˜ˆå€¼è¿‡æ»¤ (é¿å…å°ç‰©ä½“è¯¯åˆ¤)
3. ä¿ç•™æ—¶åºå¹³æ»‘
"""

import time
import threading
import cv2
import numpy as np
from collections import Counter
from luma.core.interface.serial import i2c
from luma.oled.device import ssd1306
from PIL import Image, ImageDraw, ImageFont


class GestureSmoother:
    def __init__(self, window_size=5, min_confidence=3):
        self.window_size = window_size
        self.min_confidence = min_confidence
        self.history = []
        self.stable_gesture = 'none'
    
    def update(self, raw_gesture):
        self.history.append(raw_gesture)
        if len(self.history) > self.window_size:
            self.history.pop(0)
        
        if len(self.history) < self.window_size:
            return None
        
        counter = Counter(self.history)
        most_common = counter.most_common(1)[0]
        gesture, count = most_common
        
        if count >= self.min_confidence:
            if gesture != self.stable_gesture:
                self.stable_gesture = gesture
                return gesture
        return None
    
    def get_stable(self):
        return self.stable_gesture


class GestureCamera:
    def __init__(self, camera_index=1):
        self.cap = cv2.VideoCapture(camera_index)
        self.running = False
        self.current_gesture = 'none'
        self.lock = threading.Lock()
        self.frame = None
        
        if self.cap.isOpened():
            print("[OK] æ‘„åƒå¤´å·²è¿æ¥")
        else:
            print("[ERROR] æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
    
    def detect_gesture(self, frame):
        """ä¼˜åŒ–åçš„æ‰‹åŠ¿æ£€æµ‹é€»è¾‘"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # HSV è‚¤è‰²èŒƒå›´
        lower_skin = np.array([0, 20, 70])
        upper_skin = np.array([20, 255, 255])
        mask1 = cv2.inRange(hsv, lower_skin, upper_skin)
        
        lower_skin2 = np.array([170, 20, 70])
        upper_skin2 = np.array([180, 255, 255])
        mask2 = cv2.inRange(hsv, lower_skin2, upper_skin2)
        
        mask = mask1 + mask2
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            max_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(max_contour)
            
            # é¢ç§¯è¿‡æ»¤ï¼šå¤ªå°çš„å¯èƒ½æ˜¯å™ªå£°
            if area > 5000:
                x, y, w, h = cv2.boundingRect(max_contour)
                aspect_ratio = float(w) / h
                
                hull = cv2.convexHull(max_contour, returnPoints=False)
                if len(hull) > 3:
                    defects = cv2.convexityDefects(max_contour, hull)
                    if defects is not None:
                        finger_count = 0
                        for i in range(defects.shape[0]):
                            s, e, f, d = defects[i, 0]
                            if d > 10000:
                                finger_count += 1
                        
                        # ğŸ”¥ ç»ˆæä¼˜åŒ–ï¼šæ¡æ‹³æ¡ä»¶æ”¾å®½
                        if finger_count >= 4:
                            return 'open_palm'      # å¼ å¼€æ‰‹æŒ
                        elif finger_count == 2:
                            return 'peace'          # å‰ªåˆ€æ‰‹
                        elif finger_count <= 2:     # âœ… æ¡æ‹³ï¼šç¼ºé™·æ•° <= 2 (åŸç‰ˆæ˜¯ <= 1)
                            return 'fist'           # æ¡æ‹³
                        # æ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰é•¿å®½æ¯”é™åˆ¶äº†ï¼
        
        return 'none'
    
    def run(self):
        self.running = True
        print("[INFO] æ‘„åƒå¤´è¿è¡Œä¸­ï¼Œè¯·å±•ç¤ºæ‰‹åŠ¿...")
        
        while self.running:
            ret, frame = self.cap.read()
            if not ret:
                continue
            
            frame = cv2.flip(frame, 1)
            self.frame = frame
            
            gesture = self.detect_gesture(frame)
            
            with self.lock:
                self.current_gesture = gesture
        
        self.cap.release()
        print("[OK] æ‘„åƒå¤´å·²å…³é—­")
    
    def get_gesture(self):
        with self.lock:
            return self.current_gesture
    
    def get_frame(self):
        return self.frame
    
    def stop(self):
        self.running = False


class OLEDDisplay:
    def __init__(self, port=1, address=0x3C):
        try:
            serial = i2c(port=port, address=address)
            self.device = ssd1306(serial, width=128, height=64)
            self.connected = True
            try:
                self.font_emoji = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 24)
                self.font_text = ImageFont.truetype("/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc", 14)
                self.font_small = ImageFont.truetype("/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc", 11)
            except:
                self.font_emoji = ImageFont.load_default()
                self.font_text = ImageFont.load_default()
                self.font_small = ImageFont.load_default()
            print("[OK] OLED å·²è¿æ¥")
        except Exception as e:
            self.connected = False
            print(f"[ERROR] OLED è¿æ¥å¤±è´¥: {e}")
    
    def show(self, emoji, name, action):
        if not self.connected:
            return
        
        image = Image.new('1', (128, 64))
        draw = ImageDraw.Draw(image)
        draw.rectangle((0, 0, 127, 63), outline=0, fill=0)
        
        bbox = draw.textbbox((0, 0), emoji, font=self.font_emoji)
        x = (128 - (bbox[2] - bbox[0])) // 2
        draw.text((x, 0), emoji, font=self.font_emoji, fill=255)
        
        bbox = draw.textbbox((0, 0), name, font=self.font_text)
        x = (128 - (bbox[2] - bbox[0])) // 2
        draw.text((x, 30), name, font=self.font_text, fill=255)
        
        bbox = draw.textbbox((0, 0), action, font=self.font_small)
        x = (128 - (bbox[2] - bbox[0])) // 2
        draw.text((x, 48), action, font=self.font_small, fill=255)
        
        self.device.display(image)
    
    def clear(self):
        if self.connected:
            self.device.clear()


def main():
    print("=" * 60)
    print("  ğŸ¤š æ‰‹åŠ¿è¯†åˆ«ç»ˆæä¼˜åŒ–ç‰ˆ (è§£å†³æ¡æ‹³é—®é¢˜)")
    print("=" * 60)
    print()
    print("ğŸ”¥ æ ¸å¿ƒæ”¹è¿›:")
    print("  âœ“ æ¡æ‹³æ¡ä»¶: ç¼ºé™·æ•° <= 2 (åŸç‰ˆæ˜¯ <= 1)")
    print("  âœ“ ç§»é™¤é•¿å®½æ¯”é™åˆ¶ï¼Œæ›´ç¨³å®š")
    print("  âœ“ ä¿ç•™5å¸§æ—¶åºå¹³æ»‘")
    print()
    print("è¯´æ˜: å¼ å¼€æ‰‹æŒ / æ¡æ‹³ / å‰ªåˆ€æ‰‹")
    print("æŒ‰ Ctrl+C é€€å‡º")
    print()
    
    gestures = {
        'none': ('(-_-)', 'æœªè¯†åˆ«', 'è¯·å±•ç¤ºæ‰‹åŠ¿'),
        'open_palm': ('(âœ§Ï‰âœ§)', 'å¼ å¼€æ‰‹æŒ', 'ä½ å¥½ï¼'),
        'fist': ('(â—£_â—¢)', 'æ¡æ‹³', 'åŠ æ²¹ï¼'),
        'peace': ('(â— â€¿â— )', 'å‰ªåˆ€æ‰‹', 'è€¶ï¼'),
    }
    
    camera = GestureCamera(0)
    oled = OLEDDisplay()
    smoother = GestureSmoother(window_size=5, min_confidence=3)
    
    if not camera.cap.isOpened():
        print("[ERROR] æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥")
        exit(1)
    
    camera_thread = threading.Thread(target=camera.run)
    camera_thread.start()
    
    current_display = 'none'
    
    try:
        while True:
            raw_gesture = camera.get_gesture()
            stable_gesture = smoother.update(raw_gesture)
            
            if stable_gesture is not None and stable_gesture != current_display:
                emoji, name, action = gestures.get(stable_gesture, gestures['none'])
                oled.show(emoji, name, action)
                print(f"[è¯†åˆ«] {name} {emoji} - {action}")
                current_display = stable_gesture
            
            # å¯é€‰ï¼šæ˜¾ç¤ºè°ƒè¯•ç”»é¢
            frame = camera.get_frame()
            if frame is not None:
                # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                stable = smoother.get_stable()
                raw_text = f"Raw: {raw_gesture}"
                stable_text = f"Stable: {stable}"
                cv2.putText(frame, raw_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame, stable_text, (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                cv2.imshow("Gesture Debug", frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            time.sleep(0.03)
    
    except KeyboardInterrupt:
        print("\né€€å‡ºä¸­...")
    
    finally:
        camera.stop()
        camera_thread.join()
        oled.clear()
        cv2.destroyAllWindows()
        print("[OK] å·²é€€å‡º")


if __name__ == "__main__":
    main()
