#!/usr/bin/env python3
# -*- coding:UTF-8 -*-
"""
ç‰©å“æ£€æµ‹æ¨¡å—
åŸºäºOpenCVé¢œè‰²è¯†åˆ«çš„ç‰©å“æ£€æµ‹
"""

import cv2
import numpy as np


class ObjectDetector:
    """ç‰©å“æ£€æµ‹å™¨"""

    # é¢„è®¾ç‰©å“é¢œè‰²èŒƒå›´ (HSVæ ¼å¼)
    COLOR_RANGES = {
        "çº¸å·¾": {  # ç™½è‰²/æµ…è‰²
            "lower": np.array([0, 0, 180]),
            "upper": np.array([180, 50, 255])
        },
        "èåœ": {  # æ©™è‰²
            "lower": np.array([0, 100, 100]),
            "upper": np.array([25, 255, 255])
        },
        "è‹¹æœ": {  # çº¢è‰²
            "lower": np.array([0, 100, 100]),
            "upper": np.array([10, 255, 255])
        },
        "é¦™è•‰": {  # é»„è‰²
            "lower": np.array([20, 100, 100]),
            "upper": np.array([35, 255, 255])
        },
        "ç»¿è‰²": {  # ç»¿è‰²ç‰©å“
            "lower": np.array([35, 50, 50]),
            "upper": np.array([85, 255, 255])
        },
        "è“è‰²": {  # è“è‰²ç‰©å“
            "lower": np.array([100, 50, 50]),
            "upper": np.array([130, 255, 255])
        },
    }

    # ç‰©å“ä½ç½®æ˜ å°„ (æµ‹è¯•æ¨¡å¼ä¸‹ä½¿ç”¨)
    TEST_OBJECTS = {
        "çº¸å·¾": (100, 300),
        "èåœ": (400, 300),
        "è‹¹æœ": (700, 300),
    }

    def __init__(self, camera_index=0, use_camera=True):
        self.use_camera = use_camera
        self.cap = None

        if use_camera:
            self.cap = cv2.VideoCapture(camera_index)
            if not self.cap.isOpened():
                print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                self.use_camera = False

        # é»˜è®¤å‚æ•°
        self.min_area = 1000  # æœ€å°æ£€æµ‹åŒºåŸŸ
        self.frame_width = 640
        self.frame_height = 480

    def set_resolution(self, width=640, height=480):
        """è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡"""
        if self.cap:
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            self.frame_width = width
            self.frame_height = height

    def detect_object(self, object_name, frame=None):
        """
        æ£€æµ‹æŒ‡å®šç‰©å“çš„ä½ç½®

        Args:
            object_name: ç‰©å“åç§° (çº¸å·¾/èåœ/è‹¹æœ/é¦™è•‰/ç»¿è‰²/è“è‰²)
            frame: è¾“å…¥ç”»é¢ (Noneè¡¨ç¤ºä»æ‘„åƒå¤´è·å–)

        Returns:
            dict: {
                "found": bool,
                "x": int,           # ç‰©å“ä¸­å¿ƒxåæ ‡
                "y": int,           # ç‰©å“ä¸­å¿ƒyåæ ‡
                "area": int,        # æ£€æµ‹åŒºåŸŸé¢ç§¯
                "frame": numpy.ndarray  # æ ‡æ³¨åçš„ç”»é¢
            }
        """
        if frame is None and self.use_camera:
            ret, frame = self.cap.read()
            if not ret:
                return {"found": False, "x": 0, "y": 0, "area": 0, "frame": None}

        if frame is None:
            # æµ‹è¯•æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿä½ç½®
            if object_name in self.TEST_OBJECTS:
                x, y = self.TEST_OBJECTS[object_name]
                return {
                    "found": True,
                    "x": x,
                    "y": y,
                    "area": 5000,
                    "frame": None
                }
            return {"found": False, "x": 0, "y": 0, "area": 0, "frame": None}

        # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        # è·å–é¢œè‰²èŒƒå›´
        if object_name in self.COLOR_RANGES:
            lower = self.COLOR_RANGES[object_name]["lower"]
            upper = self.COLOR_RANGES[object_name]["upper"]
        else:
            # é»˜è®¤ç™½è‰²
            lower = np.array([0, 0, 180])
            upper = np.array([180, 50, 255])

        # é¢œè‰²é˜ˆå€¼
        mask = cv2.inRange(hsv, lower, upper)

        # å½¢æ€å­¦å¤„ç†
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

        # è½®å»“æ£€æµ‹
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # æ‰¾æœ€å¤§è½®å»“
        max_area = 0
        max_contour = None

        for contour in contours:
            area = cv2.contourArea(contour)
            if area > max_area and area > self.min_area:
                max_area = area
                max_contour = contour

        # ç»˜åˆ¶ç»“æœ
        result_frame = frame.copy()

        if max_contour is not None:
            # è®¡ç®—ä¸­å¿ƒç‚¹
            M = cv2.moments(max_contour)
            if M["m00"] > 0:
                x = int(M["m10"] / M["m00"])
                y = int(M["m01"] / M["m00"])

                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                x1, y1, w, h = cv2.boundingRect(max_contour)
                cv2.rectangle(result_frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)

                # ç»˜åˆ¶ä¸­å¿ƒç‚¹
                cv2.circle(result_frame, (x, y), 5, (0, 0, 255), -1)

                # æ˜¾ç¤ºæ ‡ç­¾
                cv2.putText(result_frame, object_name, (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                return {
                    "found": True,
                    "x": x,
                    "y": y,
                    "area": max_area,
                    "frame": result_frame
                }

        # æœªæ‰¾åˆ°
        cv2.putText(result_frame, f"æœªæ£€æµ‹åˆ°{object_name}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        return {
            "found": False,
            "x": 0,
            "y": 0,
            "area": 0,
            "frame": result_frame
        }

    def scan_objects(self, frame=None):
        """
        æ‰«æç”»é¢ä¸­æ‰€æœ‰å¯è¯†åˆ«çš„ç‰©å“

        Returns:
            list: æ£€æµ‹åˆ°çš„ç‰©å“åˆ—è¡¨
        """
        detected = []

        if frame is None and self.use_camera:
            ret, frame = self.cap.read()
            if not ret:
                return []

        for object_name in self.COLOR_RANGES:
            result = self.detect_object(object_name, frame)
            if result["found"]:
                detected.append({
                    "name": object_name,
                    "x": result["x"],
                    "y": result["y"],
                    "area": result["area"]
                })

        return detected

    def get_frame(self):
        """è·å–å½“å‰å¸§"""
        if self.cap:
            ret, frame = self.cap.read()
            if ret:
                return frame
        return None

    def release(self):
        """é‡Šæ”¾æ‘„åƒå¤´"""
        if self.cap:
            self.cap.release()
        print("ğŸ“· æ‘„åƒå¤´å·²é‡Šæ”¾")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=== ç‰©å“æ£€æµ‹å™¨æµ‹è¯• ===")
    print("è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. æ‘„åƒå¤´æµ‹è¯•")
    print("2. æ¨¡æ‹Ÿæµ‹è¯•")

    mode = input("è¾“å…¥é€‰é¡¹: ").strip()

    detector = ObjectDetector(use_camera=(mode == "1"))

    if mode == "1":
        print("æŒ‰ 'q' é€€å‡ºæµ‹è¯•")
        while True:
            frame = detector.get_frame()
            if frame is not None:
                # æ˜¾ç¤ºç”»é¢
                cv2.imshow("Object Detection", frame)

                # æŒ‰qé€€å‡º
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
    else:
        # æ¨¡æ‹Ÿæµ‹è¯•
        print("\næ¨¡æ‹Ÿæ£€æµ‹ç»“æœ:")
        for obj in ["çº¸å·¾", "èåœ", "è‹¹æœ"]:
            result = detector.detect_object(obj)
            status = "âœ… æ‰¾åˆ°" if result["found"] else "âŒ æœªæ‰¾åˆ°"
            print(f"  {obj}: {status}")

    detector.release()
    print("æµ‹è¯•å®Œæˆ")
