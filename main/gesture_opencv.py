#!/usr/bin/env python3
"""
æ‰‹åŠ¿è¯†åˆ« - OpenCVç‰ˆæœ¬ (å¸¦èˆµæœºæ§åˆ¶)
ä½¿ç”¨è‚¤è‰²æ£€æµ‹è¿›è¡Œæ‰‹åŠ¿è¯†åˆ« + åŒèˆµæœºäº‘å°
"""

import time
import threading
import sys
import cv2
import numpy as np
from collections import Counter
from luma.core.interface.serial import i2c
from luma.oled.device import ssd1306
from PIL import Image, ImageDraw, ImageFont

# å¯¼å…¥ RPi.GPIO
try:
    import RPi.GPIO as GPIO

    GPIO_AVAILABLE = True
except ImportError:
    GPIO_AVAILABLE = False
    print("[è­¦å‘Š] RPi.GPIO ä¸å¯ç”¨")


# ==================== åŒèˆµæœºäº‘å°æ§åˆ¶ ====================
class ServoController:
    def __init__(self, up_down_pin=9, left_right_pin=11):
        self.up_down_pin = up_down_pin
        self.left_right_pin = left_right_pin
        self.pwm_up_down = None
        self.pwm_left_right = None
        self._is_busy = False  # æ·»åŠ å¿™æ ‡å¿—ï¼Œé˜²æ­¢åŠ¨ä½œé‡å 

        if GPIO_AVAILABLE:
            try:
                GPIO.setmode(GPIO.BCM)
                GPIO.setwarnings(False)

                # åˆå§‹åŒ–ä¸Šä¸‹èˆµæœº (GPIO 9)
                GPIO.setup(self.up_down_pin, GPIO.OUT)
                self.pwm_up_down = GPIO.PWM(self.up_down_pin, 50)
                self.pwm_up_down.start(0)
                self._set_angle_single(self.pwm_up_down, 90)

                # åˆå§‹åŒ–å·¦å³èˆµæœº (GPIO 11)
                GPIO.setup(self.left_right_pin, GPIO.OUT)
                self.pwm_left_right = GPIO.PWM(self.left_right_pin, 50)
                self.pwm_left_right.start(0)
                self._set_angle_single(self.pwm_left_right, 90)

                print("[OK] åŒèˆµæœºäº‘å°å°±ç»ª (GPIO 9=ä¸Šä¸‹, GPIO 11=å·¦å³)")
            except Exception as e:
                print(f"[é”™è¯¯] èˆµæœº: {e}")

    def _set_angle_single(self, pwm, angle, duration=0.5):
        """è®¾ç½®å•ä¸ªèˆµæœºè§’åº¦ï¼ŒæŒç»­å‘é€ä¿¡å·ä¿è¯æµç•…"""
        angle = max(0, min(180, angle))
        if pwm:
            duty = 2.5 + 10 * angle / 180.0
            pwm.ChangeDutyCycle(duty)
            time.sleep(duration)  # æŒç»­å‘é€ä¿¡å·ä¸€æ®µæ—¶é—´
            pwm.ChangeDutyCycle(0)  # ç„¶ååœæ­¢ï¼Œé˜²æ­¢æŠ–åŠ¨

    def execute_action(self, action_name):
        def action():
            if not GPIO_AVAILABLE:
                return

            # å¦‚æœæ­£åœ¨æ‰§è¡ŒåŠ¨ä½œï¼Œè·³è¿‡
            if self._is_busy:
                return

            self._is_busy = True
            print(f"[èˆµæœº] æ‰§è¡ŒåŠ¨ä½œ: {action_name}")

            if action_name == "nod":  # ç‚¹å¤´ - ä¸Šä¸‹èˆµæœºåŠ¨ (70Â°-100Â°)
                for _ in range(2):
                    self._set_angle_single(self.pwm_up_down, 100, duration=0.3)  # æŠ¬å¤´
                    self._set_angle_single(self.pwm_up_down, 70, duration=0.3)  # ä½å¤´
                self._set_angle_single(self.pwm_up_down, 90, duration=0.3)  # å›åˆ°åŸä½

            elif action_name == "shake":  # æ‘‡å¤´ - å·¦å³èˆµæœºåŠ¨ (60Â°-120Â°)
                for _ in range(3):
                    self._set_angle_single(
                        self.pwm_left_right, 60, duration=0.25
                    )  # å·¦è½¬
                    self._set_angle_single(
                        self.pwm_left_right, 120, duration=0.25
                    )  # å³è½¬
                self._set_angle_single(
                    self.pwm_left_right, 90, duration=0.3
                )  # å›åˆ°åŸä½

            elif action_name == "sway":  # æ‘‡æ‘† - å·¦å³èˆµæœº
                for _ in range(2):
                    self._set_angle_single(self.pwm_left_right, 75, duration=0.4)
                    self._set_angle_single(self.pwm_left_right, 105, duration=0.4)
                self._set_angle_single(
                    self.pwm_left_right, 90, duration=0.3
                )  # å›åˆ°åŸä½

            elif action_name == "scan":  # æ‰«æ - å·¦å³èˆµæœºç¯é¡¾
                for a in range(0, 181, 10):
                    self._set_angle_single(self.pwm_left_right, a, duration=0.08)
                for a in range(180, -1, -10):
                    self._set_angle_single(self.pwm_left_right, a, duration=0.08)
                self._set_angle_single(self.pwm_left_right, 90, duration=0.3)

            elif action_name == "look_left":  # çœ‹å·¦è¾¹
                self._set_angle_single(self.pwm_left_right, 60)

            elif action_name == "look_right":  # çœ‹å³è¾¹
                self._set_angle_single(self.pwm_left_right, 120)

            elif action_name == "look_up":  # æŠ¬å¤´
                self._set_angle_single(self.pwm_up_down, 70)

            elif action_name == "look_down":  # ä½å¤´
                self._set_angle_single(self.pwm_up_down, 100)

            elif action_name == "center":  # å›ä¸­
                self._set_angle_single(self.pwm_up_down, 90)
                self._set_angle_single(self.pwm_left_right, 90)

            elif action_name == "lock":  # é”å®š
                pass

            self._is_busy = False  # åŠ¨ä½œå®Œæˆï¼Œé‡Šæ”¾æ ‡å¿—

        threading.Thread(target=action, daemon=True).start()

    def stop(self):
        if self.pwm_up_down:
            self.pwm_up_down.stop()
        if self.pwm_left_right:
            self.pwm_left_right.stop()
        if GPIO_AVAILABLE:
            GPIO.cleanup()


class GestureSmoother:
    def __init__(self, window_size=5, min_confidence=3):
        self.window_size = window_size
        self.min_confidence = min_confidence
        self.history = []
        self.stable_gesture = "none"

    def update(self, raw_gesture):
        self.history.append(raw_gesture)
        if len(self.history) > self.window_size:
            self.history.pop(0)

        if len(self.history) < self.window_size:
            return None

        counter = Counter(self.history)
        most_common = counter.most_common(1)[0]
        gesture, count = most_common

        if count >= self.min_confidence:
            if gesture != self.stable_gesture:
                self.stable_gesture = gesture
                return gesture
        return None

    def get_stable(self):
        return self.stable_gesture


class GestureCamera:
    """OpenCVæ‰‹åŠ¿è¯†åˆ«"""

    def __init__(self, camera_index=0):
        self.cap = cv2.VideoCapture(camera_index)
        self.running = False
        self.current_gesture = "none"
        self.lock = threading.Lock()
        self.frame = None
        self.mask_frame = None
        self.debug_info = {"area": 0, "aspect_ratio": 0.0, "defects": 0}

        if self.cap.isOpened():
            print("[OK] æ‘„åƒå¤´å·²è¿æ¥")
        else:
            print("[ERROR] æ— æ³•æ‰“å¼€æ‘„åƒå¤´")

    def detect_gesture(self, frame):
        """ä½¿ç”¨è‚¤è‰²æ£€æµ‹è¯†åˆ«æ‰‹åŠ¿"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        # HSVè‚¤è‰²èŒƒå›´
        lower_skin = np.array([0, 20, 70])
        upper_skin = np.array([20, 255, 255])
        mask1 = cv2.inRange(hsv, lower_skin, upper_skin)

        lower_skin2 = np.array([170, 20, 70])
        upper_skin2 = np.array([180, 255, 255])
        mask2 = cv2.inRange(hsv, lower_skin2, upper_skin2)

        mask = mask1 + mask2
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        self.mask_frame = mask

        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            max_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(max_contour)

            if area > 5000:
                x, y, w, h = cv2.boundingRect(max_contour)
                aspect_ratio = float(w) / h

                hull = cv2.convexHull(max_contour, returnPoints=False)
                hull_points = len(hull) if hull is not None else 0

                finger_count = 0
                if hull_points > 3:
                    defects = cv2.convexityDefects(max_contour, hull)
                    if defects is not None:
                        for i in range(defects.shape[0]):
                            s, e, f, d = defects[i, 0]
                            if d > 10000:
                                finger_count += 1

                self.debug_info = {
                    "area": int(area),
                    "aspect_ratio": round(aspect_ratio, 2),
                    "defects": finger_count,
                    "hull_points": hull_points,
                }

                # æ‰‹åŠ¿åˆ¤æ–­
                if finger_count >= 4:
                    return "open_palm"
                elif finger_count == 2:
                    return "peace"
                elif finger_count <= 1:
                    return "fist"
                elif finger_count <= 2 and aspect_ratio > 0.6:
                    return "fist"

        self.debug_info = {"area": 0, "aspect_ratio": 0.0, "defects": 0}
        return "none"

    def run(self):
        self.running = True
        print("[INFO] æ‘„åƒå¤´è¿è¡Œä¸­...")

        while self.running:
            ret, frame = self.cap.read()
            if not ret:
                continue

            frame = cv2.flip(frame, 1)
            self.frame = frame

            gesture = self.detect_gesture(frame)

            with self.lock:
                self.current_gesture = gesture

        self.cap.release()
        print("[OK] æ‘„åƒå¤´å·²å…³é—­")

    def get_gesture(self):
        with self.lock:
            return self.current_gesture

    def get_frame(self):
        return self.frame

    def get_debug_info(self):
        return self.debug_info

    def stop(self):
        self.running = False


class OLEDDisplay:
    def __init__(self, port=1, address=0x3C):
        try:
            serial = i2c(port=port, address=address)
            self.device = ssd1306(serial, width=128, height=64)
            self.connected = True
            try:
                self.font_emoji = ImageFont.truetype(
                    "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 24
                )
                self.font_text = ImageFont.truetype(
                    "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc", 14
                )
                self.font_small = ImageFont.truetype(
                    "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc", 11
                )
            except:
                self.font_emoji = ImageFont.load_default()
                self.font_text = ImageFont.load_default()
                self.font_small = ImageFont.load_default()
            print("[OK] OLED å·²è¿æ¥")
        except Exception as e:
            self.connected = False
            print(f"[è­¦å‘Š] OLED: {e}")

    def show(self, emoji, name, action):
        if not self.connected:
            return

        image = Image.new("1", (128, 64))
        draw = ImageDraw.Draw(image)
        draw.rectangle((0, 0, 127, 63), outline=0, fill=0)

        bbox = draw.textbbox((0, 0), emoji, font=self.font_emoji)
        x = (128 - (bbox[2] - bbox[0])) // 2
        draw.text((x, 0), emoji, font=self.font_emoji, fill=255)

        bbox = draw.textbbox((0, 0), name, font=self.font_text)
        x = (128 - (bbox[2] - bbox[0])) // 2
        draw.text((x, 30), name, font=self.font_text, fill=255)

        bbox = draw.textbbox((0, 0), action, font=self.font_small)
        x = (128 - (bbox[2] - bbox[0])) // 2
        draw.text((x, 48), action, font=self.font_small, fill=255)

        self.device.display(image)

    def clear(self):
        if self.connected:
            self.device.clear()


def main():
    headless = "--headless" in sys.argv or "-h" in sys.argv

    print("=" * 60)
    print("  ğŸ¤š OpenCV æ‰‹åŠ¿è¯†åˆ«")
    print("=" * 60)
    print()
    print("æ‰‹åŠ¿: æ‰‹æŒ(å¼ å¼€) / æ‹³å¤´(æ¡ç´§) / å‰ªåˆ€æ‰‹(2æŒ‡)")
    print()

    gestures = {
        "none": ("(-_-)", "æœªè¯†åˆ«", "è¯·å±•ç¤ºæ‰‹åŠ¿"),
        "open_palm": ("(âœ§Ï‰âœ§)", "å¼ å¼€æ‰‹æŒ", "ä½ å¥½ï¼"),
        "fist": ("(â—£_â—¢)", "æ¡æ‹³", "åŠ æ²¹ï¼"),
        "peace": ("(â— â€¿â— )", "å‰ªåˆ€æ‰‹", "è€¶ï¼"),
    }

    # è‡ªåŠ¨æ£€æµ‹æ‘„åƒå¤´
    camera = None
    for idx in [0, 1]:
        print(f"[ä¿¡æ¯] å°è¯• /dev/video{idx}...")
        cam = GestureCamera(idx)
        if cam.cap.isOpened():
            ret, frame = cam.cap.read()
            if ret and frame is not None:
                camera = cam
                print(f"[OK] ä½¿ç”¨ /dev/video{idx}")
                break
            cam.cap.release()

    if camera is None:
        print("[ERROR] æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return

    oled = OLEDDisplay()
    smoother = GestureSmoother()
    servo = ServoController()  # åˆå§‹åŒ–èˆµæœº

    # æ‰‹åŠ¿å¯¹åº”çš„èˆµæœºåŠ¨ä½œ
    servo_actions = {
        "open_palm": "scan",  # æ‰‹æŒ -> ç¯é¡¾
        "fist": "lock",  # æ¡æ‹³ -> é”å®š
        "peace": "sway",  # å‰ªåˆ€æ‰‹ -> æ‘‡æ‘†
    }

    camera_thread = threading.Thread(target=camera.run)
    camera_thread.start()

    current_display = "none"
    frame_count = 0

    print("\n[è¿è¡Œä¸­] è¯·åœ¨æ‘„åƒå¤´å‰å±•ç¤ºæ‰‹åŠ¿...")
    print("æŒ‰ Ctrl+C é€€å‡º" if headless else "æŒ‰ Q é€€å‡º")
    print()

    try:
        while True:
            raw_gesture = camera.get_gesture()
            stable_gesture = smoother.update(raw_gesture)
            debug = camera.get_debug_info()

            if stable_gesture is not None and stable_gesture != current_display:
                emoji, name, action = gestures.get(stable_gesture, gestures["none"])
                oled.show(emoji, name, action)
                print(
                    f"[è¯†åˆ«] {name} {emoji} (é¢ç§¯:{debug['area']} ç¼ºé™·:{debug['defects']})"
                )
                # æ‰§è¡ŒèˆµæœºåŠ¨ä½œ
                servo.execute_action(servo_actions.get(stable_gesture, "center"))
                time.sleep(2)  # æš‚åœ2ç§’ç»™èˆµæœºåšåé¦ˆåŠ¨ä½œ
                current_display = stable_gesture

            if not headless:
                frame = camera.get_frame()
                if frame is not None:
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯åˆ°ç”»é¢
                    cv2.putText(
                        frame,
                        f"Gesture: {raw_gesture}",
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (0, 255, 0),
                        2,
                    )
                    info = f"A:{debug['area']} D:{debug['defects']}"
                    cv2.putText(
                        frame,
                        info,
                        (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 0),
                        2,
                    )

                    cv2.imshow("Gesture", frame)
                    if cv2.waitKey(1) & 0xFF == ord("q"):
                        break
            else:
                frame_count += 1
                if frame_count % 100 == 0:
                    print(f"[è°ƒè¯•] å·²å¤„ç† {frame_count} å¸§")
                time.sleep(0.03)

    except KeyboardInterrupt:
        print("\né€€å‡ºä¸­...")

    finally:
        camera.stop()
        camera_thread.join()
        oled.clear()
        servo.stop()  # åœæ­¢èˆµæœº
        if not headless:
            cv2.destroyAllWindows()
        print("[OK] å·²é€€å‡º")


if __name__ == "__main__":
    main()
